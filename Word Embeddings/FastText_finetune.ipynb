{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import fasttext\n",
    "import gzip\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install fasttext-wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Paths to the .gz file and the output .bin file\n",
    "#gz_file_path = r\"C:\\Users\\Rizvi\\Desktop\\FastText_BiLSTM\\cc.bn.300.bin.gz\"\n",
    "bin_file_path = r\"E:\\Bangla-Sentiment-Analysis\\Word Embeddings\\cc.bn.300.bin\"\n",
    "\n",
    "# Extract the .bin file from the .gz archive\n",
    "# with gzip.open(gz_file_path, 'rb') as f_in:\n",
    "#     with open(bin_file_path, 'wb') as f_out:\n",
    "#         shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the extracted FastText model\n",
    "fasttext_model = fasttext.load_model(bin_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Load the preprocessed dataset\n",
    "# df = pd.read_excel(r\"C:\\Users\\Rizvi\\Desktop\\Bilstm_Bangla\\data_fil_preprocessed.xlsx\")\n",
    "\n",
    "# df = df[['clean_sentence', 'Sentiment']]\n",
    "# df2 = pd.read_excel(r\"C:\\Users\\Rizvi\\Desktop\\Bilstm_Bangla\\product_reviews_bn_translated.xlsx\")\n",
    "# df2.head()\n",
    "# df2 = df2[['translated_sentence', 'Sentiment']]\n",
    "# # Rename columns to have a common name for reviews\n",
    "# df2 = df2.rename(columns={'translated_sentence': 'clean_sentence'})\n",
    "# df = df.rename(columns={'clean_sentence': 'clean_sentence'})\n",
    "\n",
    "# # Concatenate the DataFrames vertically\n",
    "# all_reviews_df = pd.concat([df, df2], axis=0, ignore_index=True)\n",
    "\n",
    "# # Print the shape of the concatenated DataFrame\n",
    "# print(\"Shape of the concatenated DataFrame:\", all_reviews_df.shape)\n",
    "# df=all_reviews_df\n",
    "\n",
    "# df.shape\n",
    "\n",
    "df = pd.read_excel(r\"E:\\Bangla-Sentiment-Analysis\\Bangla_Dataset\\final_preprocessed_dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>তেমন ভালো না কিন্তু চলার মত আছে কিন্তু এই বাজে...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>পন্যটা মোটামুটি বেশ ভালো</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>প্রোডাকটি ভালো নয় চার্জ একেবারে কম যায় ব্যাট...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>পোডাক্ট মোটামুটি ভালোই বলা চলে কিন্তু ক্লিপ লা...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>খুবি ভালো মেশিন ব্যবহার করার পর রিভিউ দিলাম</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      clean_sentence Sentiment\n",
       "0  তেমন ভালো না কিন্তু চলার মত আছে কিন্তু এই বাজে...  Negative\n",
       "1                           পন্যটা মোটামুটি বেশ ভালো  Positive\n",
       "2  প্রোডাকটি ভালো নয় চার্জ একেবারে কম যায় ব্যাট...  Negative\n",
       "3  পোডাক্ট মোটামুটি ভালোই বলা চলে কিন্তু ক্লিপ লা...  Negative\n",
       "4        খুবি ভালো মেশিন ব্যবহার করার পর রিভিউ দিলাম  Positive"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Precision: 0.6714\n",
      "Validation Recall: 0.6714\n",
      "Predicted label: __label__Positive\n",
      "Probability: 0.9914\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to convert DataFrame to FastText format and save to file\n",
    "def dataframe_to_fasttext(df, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:  # Specify encoding\n",
    "        for index, row in df.iterrows():\n",
    "            label = f\"__label__{row['Sentiment']}\"\n",
    "            text = row['clean_sentence']\n",
    "            f.write(f\"{label} {text}\\n\")\n",
    "\n",
    "# Define file paths\n",
    "train_file = 'train.txt'\n",
    "valid_file = 'valid.txt'\n",
    "\n",
    "# Assuming df is already defined and contains your data\n",
    "# Split your DataFrame into train and validation sets\n",
    "train_df = df.sample(frac=0.8, random_state=42)  # 80% for training\n",
    "valid_df = df.drop(train_df.index)  # Remaining 20% for validation\n",
    "\n",
    "# Convert and save to text files\n",
    "dataframe_to_fasttext(train_df, train_file)\n",
    "dataframe_to_fasttext(valid_df, valid_file)\n",
    "\n",
    "# Load the pre-trained FastText model\n",
    "pretrained_model_path = r\"E:\\Bangla-Sentiment-Analysis\\Word Embeddings\\cc.bn.300.bin\"  \n",
    "model = fasttext.load_model(pretrained_model_path)\n",
    "\n",
    "# Fine-tune the model on your dataset\n",
    "model = fasttext.train_supervised(\n",
    "    input=train_file,\n",
    "    epoch=15,            # Number of epochs\n",
    "    lr=0.75,              # Learning rate (consider trying lower values)\n",
    "    wordNgrams=5,        # Use bigrams\n",
    "    bucket=100000,       # Reduced bucket size for hashing\n",
    "    dim=300,             # Keep vector dimensions same as pre-trained model\n",
    "    loss='ova',      # Loss function\n",
    "    verbose=2            # Verbosity level\n",
    ")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_model(\"fine_tuned_FastText_1.bin\")\n",
    "\n",
    "# Validate the model\n",
    "num_examples, precision, recall = model.test(valid_file)\n",
    "print(f\"Validation Precision: {precision:.4f}\")\n",
    "print(f\"Validation Recall: {recall:.4f}\")\n",
    "\n",
    "# Predict the sentiment of a new sentence\n",
    "sentence = \"খুবি ভাল মেশিন   ব্যবহার করার পর রিভিউ দিলাম\t\"\n",
    "labels, probabilities = model.predict(sentence)\n",
    "print(f\"Predicted label: {labels[0]}\")\n",
    "print(f\"Probability: {probabilities[0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: __label__Negative\n",
      "Probability: 0.8222\n"
     ]
    }
   ],
   "source": [
    "# Predict the sentiment of a new sentence\n",
    "sentence = \"খুবি ফালতু মেশিন   ব্যবহার করার পর রিভিউ দিলাম\"\n",
    "labels, probabilities = model.predict(sentence)\n",
    "print(f\"Predicted label: {labels[0]}\")\n",
    "print(f\"Probability: {probabilities[0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Bangla Sentiment Analysis Thesis\\Word Embeddings C:\\Users\\Rizvi\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Print the current working directory\n",
    "print(r\"E:\\Bangla-Sentiment-Analysis\\Word Embeddings\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(r\"E:\\Bangla-Sentiment-Analysis\\Word Embeddings\", \"fine_tuned_FastText_1.bin\")\n",
    "fasttext_model.save_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
